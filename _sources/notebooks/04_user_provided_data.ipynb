{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://notebooks.dtcglaciers.org/_images/ESA_logo.svg\" width=\"160\" align='right'/>\n",
    "</div>\n",
    "\n",
    "# Creating DTC-Glaciers User-DT-Enhanced Data cubes (L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "A central aspect that distinguishes DTC Glaciers as a **Digital Twin Component** is that users are not limited to downloading pre-computed products. Instead, the system is designed to support **active interaction**, allowing users to integrate their **own data** into the workflow.\n",
    "\n",
    "This notebook introduces **Level 3 (L3) data cubes**, which are **user-driven, model–data cubes** generated by combining user-provided datasets with the DTC Glaciers modelling and assimilation framework. L3 data cubes extend the pre-computed L1 and L2 products by enabling users to explore alternative data sources, assumptions, or scenarios within the same Digital Twin architecture.\n",
    "\n",
    "In this notebook, we demonstrate how users can provide their own observational or derived data, generate corresponding **L3 data cubes**, and subsequently **validate** these against existing DTC Glaciers products.  \n",
    "This includes direct comparison with pre-computed L2 data cubes, as well as validation using user-supplied observations.\n",
    "\n",
    "The workflow illustrated here highlights how DTC Glaciers supports experimentation, hypothesis testing, and application-specific analyses, while maintaining consistency with the underlying DTC framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "If required, install the DTCG API using the following command:\n",
    "\n",
    "```\n",
    "!pip install 'dtcg[jupyter] @ git+https://github.com/DTC-Glaciers/dtcg'\n",
    "```\n",
    "\n",
    "Run this command in a notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import dtcg.integration.oggm_bindings as oggm_bindings\n",
    "import dtcg.integration.calibration as calibration\n",
    "from dtcg import DEFAULT_L2_DATACUBE_URL\n",
    "\n",
    "from oggm.core import massbalance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Preparing the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "In this example, we focus on **Iceland**, where we have example **in-situ mass balance data** from the **National Power Company of Iceland, [Landsvirkjun](https://www.landsvirkjun.com/)**, a key stakeholder of DTC-Glaciers.\n",
    "\n",
    "We concentrate on **Brúarjökull**, an outlet glacier of **[Vatnajökull](https://en.wikipedia.org/wiki/Vatnaj%C3%B6kull)**, the largest ice cap in Iceland. In the following cells, we open the example data and reproject it onto the same grid as our data cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import xarray as xr\n",
    "import salem\n",
    "\n",
    "from oggm import utils, cfg\n",
    "\n",
    "# Module logger\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "if 'iceland_smb' not in cfg.BASENAMES:\n",
    "    cfg.BASENAMES['iceland_smb'] = ('iceland_smb.nc', 'SMB for Iceland (DTCG)')\n",
    "\n",
    "file_url = 'https://cluster.klima.uni-bremen.de/~dtcg/test_files/case_study_regions/iceland/vatnajokull_SMB_maps_1996-2024_a&s_v1.nc'\n",
    "\n",
    "\n",
    "@utils.entity_task(log, writes=['iceland_smb'])\n",
    "def add_iceland_smb(gdir):\n",
    "    \"\"\"Adds SMB to the glacier directory and reprojects the data onto the L1 grid.\"\"\"\n",
    "\n",
    "    # Template dataset\n",
    "    with xr.open_dataset(gdir.get_filepath('gridded_data')) as dsg:\n",
    "        dsg = dsg[['x', 'y']].copy()\n",
    "\n",
    "    # Transform SMB to glacier map\n",
    "    with salem.open_xr_dataset(utils.file_downloader(file_url)) as ds_smb:\n",
    "        dsg = dsg.salem.transform(ds_smb[['ba', 'b']], interp='linear')\n",
    "\n",
    "    # Write it up\n",
    "    dsg.to_netcdf(gdir.get_filepath('iceland_smb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_id_ice = \"RGI60-06.00377\"  # Brúarjökull\n",
    "dtcg_oggm_ice = oggm_bindings.BindingsOggmModel(rgi_id=rgi_id_ice)\n",
    "\n",
    "def get_l2_data_tree(rgi_id):\n",
    "    return xr.open_datatree(\n",
    "            f\"{DEFAULT_L2_DATACUBE_URL}{rgi_id}.zarr\",\n",
    "            chunks={},\n",
    "            engine=\"zarr\",\n",
    "            consolidated=True,\n",
    "            decode_cf=True,\n",
    "        )\n",
    "\n",
    "data_tree_ice = get_l2_data_tree(rgi_id_ice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user data\n",
    "from oggm import workflow\n",
    "workflow.execute_entity_task(add_iceland_smb, dtcg_oggm_ice.gdir);\n",
    "\n",
    "# open user data\n",
    "with xr.open_dataset(dtcg_oggm_ice.gdir.get_filepath('iceland_smb')) as ds_user:\n",
    "    ds_user = ds_user\n",
    "ds_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Let’s take a first look at the **gridded data** and the **mean annual mass balance**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_smb = ds_user['ba'].where(dtcg_oggm_ice.l1_datacube.glacier_mask)\n",
    "avg_smb = annual_smb.mean(dim='time_a', keep_attrs=True)\n",
    "avg_smb.plot(cmap='RdBu', vmin=-10, vmax=10)\n",
    "plt.title('Mean annual mass balance 1996 to 2024')\n",
    "plt.show()\n",
    "\n",
    "annual_smb.mean(dim=('y','x')).plot();\n",
    "plt.grid('on')\n",
    "plt.title('Annual mean mass balance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Create L3 data cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The main idea of **DTC-Glaciers** is to **make it easy** for users to **interact with the system** and generate **custom model output**, rather than relying only on preprocessed, static results. Here, we demonstrate a first use case in which a user can provide **their own observations**, generate **L3 data cubes**, and further use their own data for **validation** (shown in one of the next sections).\n",
    "\n",
    "Let’s prepare the user data as **cumulative mass balance** for the period **2010–2020**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_string(date):\n",
    "    return np.datetime_as_string(date, unit=\"D\").item()\n",
    "\n",
    "start_date = annual_smb.time_a[14].values  # 2010\n",
    "end_date = annual_smb.time_a[24].values  # 2020\n",
    "\n",
    "# the period of the reference mass balance, e.g. '2010-01-01_2020-01-01'\n",
    "ref_mb_period = (f\"{get_date_string(start_date)}_\"\n",
    "                 f\"{get_date_string(end_date)}\")\n",
    "\n",
    "# the actual observation value calculated as the cumulative mass balance over the period of interest\n",
    "annual_cumsum_smb = annual_smb.mean(dim=('y','x')).cumsum()\n",
    "ref_mb = (annual_cumsum_smb.sel(time_a=end_date).values -\n",
    "          annual_cumsum_smb.sel(time_a=start_date).values\n",
    "         ) * 1000  # convert to mm w.e., which is equal to kg m-2\n",
    "\n",
    "# the unit of the provided observation\n",
    "ref_mb_unit = 'kg m-2'\n",
    "\n",
    "# an associated uncertainty, in this example we just set a typical order of magnitude\n",
    "ref_mb_err = 500\n",
    "\n",
    "# this description is add to the attributes of the resulting datacubes for reference\n",
    "calibration_strategy = (\"OGGM model DailyTIModel calibrated with user data \"\n",
    "                        f\"from Landsvirkjun over the period {ref_mb_period}.\")\n",
    "\n",
    "# this is the name which will be used when adding the datacube to a datatree\n",
    "l3_datacube_name = (f\"L3_Daily_Landsvirkjun_\"\n",
    "                    f\"{get_date_string(start_date).split('-')[0]}_\"\n",
    "                    f\"{get_date_string(end_date).split('-')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Currently, DTC-Glaciers supports calibration of the mass balance only over a **complete reference period**. However, in **OGGM** it is also possible to calibrate using an **incomplete set of mass balance observations**, for example by considering only selected years. This functionality could potentially be added to DTC-Glaciers in the future.\n",
    "\n",
    "Now we provide the user data to the calibrator and create **L3 data cubes**. For this, we use `calibrator.calibrate_mb_and_create_datacubes`, which takes as input the **mass balance model** to be calibrated and the **reference mass balance values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = calibration.CalibratorCryotempo(l1_datacube=data_tree_ice['L1'].ds,\n",
    "                                             gdir=dtcg_oggm_ice.gdir)\n",
    "\n",
    "l3_datacubes = calibrator.calibrate_mb_and_create_datacubes(\n",
    "    mb_model_class=massbalance.DailyTIModel,\n",
    "    ref_mb=ref_mb,\n",
    "    ref_mb_err=ref_mb_err,\n",
    "    ref_mb_unit=ref_mb_unit,\n",
    "    ref_mb_period=ref_mb_period,\n",
    "    calibration_strategy=calibration_strategy,\n",
    "    datacubes_requested=['monthly', 'annual_hydro', 'daily_smb'],\n",
    "    show_log=True,  # to see what is happening\n",
    "    # we set here a small ensemble number for MCS for demonstration to reduce computing time,\n",
    "    # the precomputed datacubes use 2**4~100 ensemble members\n",
    "    mcs_sampling_settings={'nr_samples': 2**1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The resulting **L3 data cube** can be added to the existing `data_tree` in the same way as the **L2 data cubes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.datacube.geozarr import GeoZarrHandler\n",
    "\n",
    "datacube_handler = GeoZarrHandler(data_tree=data_tree_ice)\n",
    "\n",
    "datacube_handler.add_layer(datacubes=l3_datacubes,\n",
    "                           datacube_name=l3_datacube_name)\n",
    "\n",
    "list(datacube_handler.data_tree.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "[![Zarr logo](https://avatars.githubusercontent.com/u/35050297?s=96&v=4)](https://github.com/zarr-developers/geozarr-spec) And could be stored locally as GeoZarr: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datacube_handler.export('datacube_including_L3.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Validate L3 data cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>IMPORTANT</b>: Please note that the current <b>L3 data cube</b> was created using a <b>smaller ensemble size</b> for the Monte Carlo simulation. Therefore, the resulting uncertainties are <b>not comparable</b> to those of the preprocessed <b>L2 data cubes</b>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The general validation of **L3 data cubes** works in the same way as for **L2**, as explained in  \n",
    "[this notebook](03_validation.ipynb). Let’s have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the datacubes which should be evaluated\n",
    "validation_name_list = ['L2_Daily_Cryosat_2011_2020',\n",
    "                        'L2_Daily_Hugonnet_2010_2020',\n",
    "                        'L3_Daily_Landsvirkjun_2010_2020'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.validation.validator import DatacubeValidator\n",
    "\n",
    "# conduct the actual validation\n",
    "validator = DatacubeValidator(datacube_handler.data_tree)\n",
    "validation_data = validator.get_validation_for_layers(l2_name_list=validation_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['WGMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['CryoSat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "We see the **L3** data cube lies somewhere in between the two other **L2** data cubes for the WGMS and CryoSat valiation. This is also confirmed when visually comparing the data in a plot:\n",
    "\n",
    "We see that the **L3 data cube** lies somewhere between the two **L2 data cubes** calibrated with **[Hugonnet et al. (2021)](https://doi.org/10.1038/s41586-021-03436-z)** and **CryoSat-2** data. This is also confirmed by a visual comparison of the results in the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.get_validation_plot_for_layers(l2_name_list=validation_name_list, obs_name='WGMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.get_validation_plot_for_layers(l2_name_list=validation_name_list, obs_name='CryoSat2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Validation with user data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Another level of **interaction** between the **user** and **DTC-Glaciers** is the ability to bring **your own data** and use the tools of the **validation framework** to evaluate the supported validation metrics or to create plots for visually inspecting differences.\n",
    "\n",
    "For this, we need to provide the user data in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_mb = annual_smb.mean(dim=('y','x'))\n",
    "\n",
    "user_observation = {\n",
    "    # Let the validation framework know which type of observation is provided\n",
    "    'obs_type': 'annual_mb',\n",
    "    # The observed values\n",
    "    'values': annual_mb.values * 1000,\n",
    "    # Corresponding uncertainties\n",
    "    'uncertainty': np.full(annual_mb.values.shape, 200),\n",
    "    # The observation years\n",
    "    'years': np.array([yr.astype('datetime64[Y]').astype(int) + 1970 for yr in annual_mb.time_a.values]),\n",
    "    # Name of the data source (displayed in the validation tables)\n",
    "    'name' : \"Landsvirkjun provided annual mass balance\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "After preparing the data, you can provide it via `user_observation` and interact with the **validation framework** in the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, bootstrap_args = validator.get_validation_for_layers(\n",
    "    user_observation=user_observation, l2_name_list=validation_name_list, return_bootstrap_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['annual_mb']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "In this case, we see that the newly generated **L3 data cube** performs **slightly better** than the other two options. This is **expected**, as parts of the user-provided data were also used for calibration, and the validation is therefore **not fully independent**.\n",
    "\n",
    "You can also provide the `user_observation` to the plotting functions to **visually compare** different data cubes with the provided observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.get_validation_plot_for_layers(user_observation=user_observation, l2_name_list=validation_name_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
