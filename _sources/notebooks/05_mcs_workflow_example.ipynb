{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "**Important**: This notebook only works together with the oggm dev branch at the moment and requires SALib to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SALib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oggm import utils, workflow, tasks, cfg\n",
    "from oggm.core.massbalance import MonthlyTIModel\n",
    "\n",
    "import SALib.sample.sobol as sampler\n",
    "import SALib.analyze.sobol as analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Set up a gdir to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.initialize(logging_level=\"WARNING\")\n",
    "\n",
    "working_dir = 'working_dir_mcs'\n",
    "utils.mkdir(working_dir)\n",
    "cfg.PATHS[\"working_dir\"] = working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "rgi_ids = [\"RGI60-06.00377\"]\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/'\n",
    "gdirs = workflow.init_glacier_directories(\n",
    "        rgi_ids,\n",
    "        from_prepro_level=3,\n",
    "        prepro_border=10,\n",
    "        prepro_rgi_version=\"62\",\n",
    "        prepro_base_url=base_url,\n",
    "    )\n",
    "\n",
    "gdir = gdirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo calibration to get the observations values stored in the observations file (prepro gdirs are not created with dev)\n",
    "workflow.execute_entity_task(tasks.mb_calibration_from_hugonnet_mb,\n",
    "                             gdirs,\n",
    "                             informed_threestep=True,  # only available for 'GSWP3_W5E5'\n",
    "                            );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Define a workflow to play with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Here you need to define a function which takes all parameters which are included in the uncertainty porpagation. Those parameters include observations (in my example reference mass balance `ref_mb`) and model parameters (in my example `melt_f`, `prcp_fac` and `temp_bias`). The function should conduct the calibration and potentially also a dynamic model run. All results should be stored using the `settings_filesuffix`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Notes on the new handling of settings and observations:\n",
    "\n",
    "- **Observations**: In observations, the convention is that the variable name should match the functionâ€™s kwarg. For example, `tasks.mb_calibration_from_scalar_mb` has the kwargs `ref_mb`, `ref_mb_period`, and `ref_mb_err`. Therefore, in the observations we use the key `ref_mb`. The actual value is stored under `observations['ref_mb']['value']`, and the other parameters are stored without repeating `ref_mb`. For example, `ref_mb_period` is stored as `observations['ref_mb']['period']`.\n",
    "- **Settings with a parent file**: A settings file can have a parent. If a parameter is not found in the current file, it will be taken from the parent. By default, the parent is `cfg.PARAMS`. You can change this by setting `parent_filesuffix`. In my example, I use this feature to ensure all parameters are consistent with the default calibration.\n",
    "- **Calibrated parameters**: After calibration, the parameters are written back into the settings file with the chosen `settings_filesuffix`. This means that after running `tasks.mb_calibration_from_scalar_mb`, you will find the calibrated parameters in the settings under this suffix. In some cases, the initial guess of a parameter may also come from the settings and later be overwritten with the calibrated values. In the future, we might want to add safeguards for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcs_mb_calibration(gdir, settings_filesuffix, settings_parent_filesuffix,\n",
    "                       observations_filesuffix,\n",
    "                       ref_mb, ref_mb_period, ref_mb_err,\n",
    "                       prcp_fac, melt_f, temp_bias,\n",
    "                      ):\n",
    "    # add observations data to observations file\n",
    "    gdir.observations_filesuffix = observations_filesuffix\n",
    "    gdir.observations['ref_mb'] = {'err': ref_mb_err,\n",
    "                                   'period': ref_mb_period,\n",
    "                                   'value': ref_mb}\n",
    "\n",
    "    # create the new settings file with the correct parent_filesuffix\n",
    "    utils.ModelSettings(gdir, filesuffix=settings_filesuffix,\n",
    "                        parent_filesuffix=settings_parent_filesuffix)\n",
    "    gdir.settings_filesuffix = settings_filesuffix\n",
    "    gdir.settings['use_winter_prcp_fac'] = False  # this is checked in mb_calibration_from_scalar_mb\n",
    "\n",
    "    # the settings here mimic mb_calibration_from_hugonnet_mb\n",
    "    workflow.execute_entity_task(tasks.mb_calibration_from_scalar_mb,\n",
    "                                 gdir,\n",
    "                                 settings_filesuffix=settings_filesuffix,\n",
    "                                 observations_filesuffix=observations_filesuffix,\n",
    "                                 overwrite_gdir=True,\n",
    "                                 calibrate_param1='prcp_fac',\n",
    "                                 calibrate_param2='melt_f',\n",
    "                                 calibrate_param3='temp_bias',\n",
    "                                 prcp_fac=prcp_fac,\n",
    "                                 prcp_fac_min=prcp_fac * 0.8,\n",
    "                                 prcp_fac_max=prcp_fac * 1.2,\n",
    "                                 melt_f=melt_f,\n",
    "                                 temp_bias=temp_bias,\n",
    "                                 mb_model_class=MonthlyTIModel,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Create sample of input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Here we define the distribution of the parameters we consider (observations and model parameters). This example here was just a quick setup for testing the principle workflow and need to be refined carefully depending on the application and the used type of observation. \n",
    "\n",
    "Here an overview which kind of distributions can be used and the meaning of 'bounds' depending on the selected distribution: https://salib.readthedocs.io/en/latest/user_guide/advanced.html#generating-alternate-distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## define parameter distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "I included here a small in between step for defining the parameters in a more readable way and only at the end convert it into the format which is expected by the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to have a better overview I provide the parameter distribution in a more readable way first\n",
    "parameter_distribution = {}\n",
    "\n",
    "# add geodetic mb observation\n",
    "gdir.observations_filesuffix = ''  # just to be sure to use the correct observations\n",
    "ref_mb = gdir.observations['ref_mb']\n",
    "parameter_distribution['ref_mb'] = {\n",
    "    'bounds': [ref_mb['value'] - ref_mb['err'],  # this need to be checked again if we should use +/-err/2\n",
    "               ref_mb['value'] + ref_mb['err']],\n",
    "    'dists': 'unif'  # need to be checked\n",
    "}\n",
    "\n",
    "# add mb parameter distributions (they are made up and need to be decided somehow)\n",
    "gdir.settings_filesuffix = ''\n",
    "parameter_distribution['prcp_fac'] = {\n",
    "    'bounds': [max(gdir.settings['prcp_fac'] * 0.5, gdir.settings['prcp_fac_min']),\n",
    "               min(gdir.settings['prcp_fac'] * 1.5, gdir.settings['prcp_fac_max'])\n",
    "              ],\n",
    "    'dists': 'unif'\n",
    "}\n",
    "parameter_distribution['melt_f'] = {\n",
    "    'bounds': [max(gdir.settings['melt_f'] - 1, gdir.settings['melt_f_min']),\n",
    "               min(gdir.settings['melt_f'] + 1, gdir.settings['melt_f_max'])],\n",
    "    'dists': 'unif'\n",
    "}\n",
    "parameter_distribution['temp_bias'] = {\n",
    "    'bounds': [max(gdir.settings['temp_bias'] - 0.5, gdir.settings['temp_bias_min']),\n",
    "               min(gdir.settings['temp_bias'] + 0.5, gdir.settings['temp_bias_max'])],\n",
    "    'dists': 'unif'\n",
    "}\n",
    "\n",
    "# now convert to format which is expected by SALib\n",
    "num_vars = 0\n",
    "problem = {\n",
    "    'names': [],\n",
    "    'bounds': [],\n",
    "    'dists': [],\n",
    "}\n",
    "\n",
    "for key in parameter_distribution:\n",
    "    num_vars += 1\n",
    "    problem['names'].append(key)\n",
    "    problem['bounds'].append(parameter_distribution[key]['bounds'])\n",
    "    problem['dists'].append(parameter_distribution[key]['dists'])\n",
    "problem['num_vars'] = num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## create actual samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Creating the actual sample is quite easy again. For more information on the sampling method you can read up the references provided in the sampler docstring `sampler.sample?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total number of samples created is \n",
    "# - including second order interconnections: N * (2 * num_vars + 2)\n",
    "# - or only look at uncorrelated sensitivity with calc_second_order=False: N * (num_vars + 2)\n",
    "N = 2**5  # if using second order this needs to be a power of 2\n",
    "param_values = sampler.sample(problem, N, calc_second_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# execute a calibration for each parameter setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Here I loop through all samples and execute my function I defined above. For this we probably could utilize multiprocessing in the future (one option would be to make our function an entity_task and use the execute_entity_task logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the reference mass balance we provide the same error and mb_period as the original observation\n",
    "gdir.observations_filesuffix = ''\n",
    "ref_mb = gdir.observations['ref_mb']\n",
    "\n",
    "for i, param_val in enumerate(param_values):\n",
    "    print(f\"{i + 1}/{param_values.shape[0]}\")\n",
    "    mcs_mb_calibration(gdir,\n",
    "                       settings_filesuffix=f'_{i}',\n",
    "                       settings_parent_filesuffix='',\n",
    "                       observations_filesuffix=f'_{i}',\n",
    "                       ref_mb_period=ref_mb['period'],\n",
    "                       ref_mb_err=ref_mb['err'],\n",
    "                       ref_mb=param_val[problem['names'].index('ref_mb')],\n",
    "                       prcp_fac=param_val[problem['names'].index('prcp_fac')],\n",
    "                       melt_f=param_val[problem['names'].index('melt_f')],\n",
    "                       temp_bias=param_val[problem['names'].index('temp_bias')],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Look at results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## resulting distribution of mb parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Here just look at the resulting mass balance parameters after calibration. We initialized all with a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default run parameters\n",
    "gdir.settings_filesuffix = ''\n",
    "prcp_fac_default = gdir.settings['prcp_fac']\n",
    "melt_f_default = gdir.settings['melt_f']\n",
    "temp_bias_default = gdir.settings['temp_bias']\n",
    "\n",
    "prcp_fac_all = []\n",
    "melt_f_all  =[]\n",
    "temp_bias_all = []\n",
    "\n",
    "for i in range(param_values.shape[0]):\n",
    "    gdir.settings_filesuffix = f'_{i}'\n",
    "    prcp_fac_all.append(gdir.settings['prcp_fac'])\n",
    "    melt_f_all.append(gdir.settings['melt_f'])\n",
    "    temp_bias_all.append(gdir.settings['temp_bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_parameter_distribution(para_all, para_default, title, bins=20):\n",
    "    plt.hist(para_all, bins=bins, color='C0')\n",
    "    plt.axvline(para_default, c='k', label='control run')\n",
    "    plt.axvline(np.median(para_all), c='C1', label='median from sample')\n",
    "    plt.axvline(np.mean(para_all), c='C1', ls='--', label='mean from sample')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plt_parameter_distribution(prcp_fac_all,\n",
    "                           prcp_fac_default,\n",
    "                           'prcp_fac',\n",
    "                           bins=20)\n",
    "\n",
    "plt_parameter_distribution(melt_f_all,\n",
    "                           melt_f_default,\n",
    "                           'melt_f',\n",
    "                           bins=20)\n",
    "\n",
    "plt_parameter_distribution(temp_bias_all,\n",
    "                           temp_bias_default,\n",
    "                           'temp_bias',\n",
    "                           bins=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## pick one year and look at distribution of resulting mb values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Here we visualize the uncertainty for the specific mass balance for the period 1980 to 2020 as defined by the MCS sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fls = gdir.read_pickle('inversion_flowlines')\n",
    "years = np.arange(1980, 2020)\n",
    "\n",
    "# get control run (= current default OGGM calibration)\n",
    "mb_mod = MonthlyTIModel(gdir, settings_filesuffix='')\n",
    "specific_mb_default = mb_mod.get_specific_mb(fls=fls, year=years)\n",
    "\n",
    "# now get values from MCS sample\n",
    "specific_mb_all = []\n",
    "for i in range(param_values.shape[0]):\n",
    "    mb_mod = MonthlyTIModel(gdir, settings_filesuffix=f'_{i}')\n",
    "    specific_mb_all.append(mb_mod.get_specific_mb(fls=fls, year=years))\n",
    "specific_mb_all = np.array(specific_mb_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(years, np.min(specific_mb_all, axis=0), np.max(specific_mb_all, axis=0),\n",
    "                 color='lightgray', label=f'range MCS sample')\n",
    "\n",
    "plt.plot(years, specific_mb_default, '-k', label='control run (default)')\n",
    "plt.plot(years, np.median(specific_mb_all, axis=0), 'C1--', label='median MCS sample')\n",
    "plt.plot(years, np.mean(specific_mb_all, axis=0), 'C2:', label='mean MCS sample')\n",
    "plt.title('Example of the uncertainties generated with MCS')\n",
    "plt.ylabel('Specific MB (mm w.e.)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Bonus: Get sensitivities (not needed at this stage of DTC-Glaciers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "This is not needed at the moment. But the idea is that you also can analyze how much of the variance of a result is comming from the observations and how much from the model parameters. This could become interesting in a next phase of DTC-Glaciers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare how much of the variance for one year is comming from the observation and how much from the model\n",
    "yr = 2000\n",
    "\n",
    "# now get values from MCS runs\n",
    "specific_mb_yr = []\n",
    "for i in range(param_values.shape[0]):\n",
    "    mb_mod = MonthlyTIModel(gdir, settings_filesuffix=f'_{i}')\n",
    "    specific_mb_yr.append(mb_mod.get_specific_mb(fls=fls, year=yr))\n",
    "specific_mb_yr = np.array(specific_mb_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = analyser.analyze(problem, specific_mb_yr, print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "How to read this (from my amateur point of few, without digging into the references):\n",
    "\n",
    "In the first order sensitivities S1 we see the largest portion of the sensitivity of the 2000 specific mass balance is comming from the precipitation factor followed by the melt_factor.\n",
    "\n",
    "To get a more indepth understanding have a look at the references provided in the docstring `analyser.analyze?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyser.analyze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
