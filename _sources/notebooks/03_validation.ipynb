{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://notebooks.dtcglaciers.org/_images/ESA_logo.svg\" width=\"160\" align='right'/>\n",
    "</div>\n",
    "\n",
    "# Validating DTC-Glaciers EO-DT-Enhanced Data cubes (L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "To assess the performance of different **L2 data cubes**, this notebook illustrates the capabilities of the **DTC Glaciers validation framework**.  \n",
    "The objective is to evaluate L2 data cubes by comparing their model-derived estimates against independent observations available from the corresponding **L1 data cubes**.\n",
    "\n",
    "This validation step is a core component of the DTC Glaciers concept, providing a transparent way to quantify consistency between observations and model-based reconstructions, and to characterise associated uncertainties.\n",
    "\n",
    "We begin by opening two examples from the pre-processed **L2 data cubes**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "If required, install the DTCG API using the following command:\n",
    "\n",
    "```\n",
    "!pip install 'dtcg[jupyter] @ git+https://github.com/DTC-Glaciers/dtcg'\n",
    "```\n",
    "\n",
    "Run this command in a notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dtcg import DEFAULT_L2_DATACUBE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_id_ice = \"RGI60-06.00377\"  # Brúarjökull\n",
    "rgi_id_aut = \"RGI60-11.00719\"  # Vernagtferner\n",
    "\n",
    "def get_l2_data_tree(rgi_id):\n",
    "    return xr.open_datatree(\n",
    "            f\"{DEFAULT_L2_DATACUBE_URL}{rgi_id}.zarr\",\n",
    "            chunks={},\n",
    "            engine=\"zarr\",\n",
    "            consolidated=True,\n",
    "            decode_cf=True,\n",
    "        )\n",
    "\n",
    "data_tree_ice = get_l2_data_tree(rgi_id_ice)\n",
    "data_tree_aut = get_l2_data_tree(rgi_id_aut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Validation of DTC-Glaciers output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The **validation** within DTC-Glaciers consists of a combination of **in-situ observations** and **Earth observation (EO) data** from the **L1 data cubes**. The entire validation framework is built around the `DatacubeValidator`, which only requires a **data tree** as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.validation.validator import DatacubeValidator\n",
    "\n",
    "validator_ice = DatacubeValidator(data_tree_ice)\n",
    "validator_aut = DatacubeValidator(data_tree_aut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We assess the performance of different **L2 data cubes** with respect to observations by calculating the following metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_ice.get_description_of_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "To account for **observation** and **model uncertainty** during validation, we rely on **[bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))**. For this purpose, the **performance metrics** are not only evaluated for the **most likely** observation and model values, but we also generate a **distribution** for each metric.\n",
    "\n",
    "This is done by repeatedly **resampling the time series** in coherent multi-year blocks and **drawing** a plausible value for each resampled year from the corresponding **uncertainty description**. For **observations**, we assume a **normal distribution**, while the **model output** is represented by **seven quantiles** (0.05, 0.15, 0.25, 0.5, 0.75, 0.85, and 0.95).\n",
    "\n",
    "By default, this procedure is **repeated 5,000 times**. The resulting sampling distribution is then summarised using a **90% confidence interval**, which is shown in brackets in the validation output below.\n",
    "\n",
    "Below, we show two examples of the validation framework for our two case study regions, which differ in their **data availability**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Iceland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "In Iceland, we have **Earth observation data** from **[CryoTEMPO-EOLIS](https://cryotempo-eolis.org/)** (CryoSat-2), as well as **in-situ observations** from **[WGMS](https://wgms.ch/)** for some glaciers.\n",
    "\n",
    "Let’s see which **L2 data cubes** are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_tree_ice.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "For the following analysis, we selected the **daily mass balance model** calibrated with **[CryoTEMPO-EOLIS](https://cryotempo-eolis.org/)** (CryoSat-2) for the period **2011–2020**. We then compared it to the same model calibrated with **[Hugonnet et al. (2021)](https://doi.org/10.1038/s41586-021-03436-z)** for the period **2010–2020**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_list_ice = ['L2_Daily_Cryosat_2011_2020', 'L2_Daily_Hugonnet_2010_2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "With the `DatacubeValidator` already set up, we only need to provide the **L2 data cubes** of interest. The validator then checks which reference data are available in the **L1 data cubes** and computes the corresponding **performance metrics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_ice, bootstrap_args_ice = validator_ice.get_validation_for_layers(\n",
    "    l2_name_list=l2_list_ice, return_bootstrap_args=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Let’s start by examining the results of comparing the **L2 data cubes** with the **CryoSat-2 observations**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_ice['CryoSat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We see that the data cube calibrated with **CryoSat-2** outperforms the one calibrated with **Hugonnet et al. (2021)**.  \n",
    "The metrics that quantify **absolute differences** (`MeanAbsD`, `RMSD`) show smaller values, indicating a better overall agreement.\n",
    "\n",
    "Metrics that quantify **bias** (`MeanD` and `MedianD`) are closer to zero, and their **confidence intervals span both positive and negative values**, suggesting no strong systematic bias. Finally, the **correlation coefficient** is higher, indicating a stronger linear relationship between the observations and the model output.\n",
    "\n",
    "To help with interpretation, we can also take a look at the **bootstrap settings** used during the validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_args_ice['CryoSat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "We see that the reported metric intervals correspond to a **90% confidence interval** (`ci_level`). In total, **173 observations** are available (`n`). The validation is based on **5,000 bootstrap resamplings** of the time series and repeated evaluations of the metrics (`n_boot`). A **block length of 13 observations** was used to preserve temporal coherence (`block_length`). For **reproducibility**, a fixed random `seed` is applied.\n",
    "\n",
    "However, it is important to note that this validation is **not fully independent**, because the CryoSat-2 data cube uses part of the same data for calibration. Therefore, we also evaluate the model performance using **independent data only** by defining a dedicated **validation period**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cryosat_2020_2025 = validator_ice.get_validation_for_layers(\n",
    "    l2_name_list=l2_list_ice,\n",
    "    baseline_date='2020-01-01',  # the date where the cumulated elevation change starts\n",
    "    obs_list=['CryoSat2'],  # we can select to only perform the validation on one observation\n",
    "    validation_period='2020-01-01_2025-12-31',)  # define the period which should be considered\n",
    "\n",
    "validation_cryosat_2020_2025['CryoSat2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Even when using the **independent validation period**, the **CryoSat-2–calibrated data cube** still outperforms the **Hugonnet-calibrated data cube**. However, the differences are **less pronounced** than when using the full time period.\n",
    "\n",
    "We can also use the `DatacubeValidator` to gain a **visual impression of model performance** by creating **comparison plots**.\n",
    "\n",
    "First, for the **entire period**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_ice.get_validation_plot_for_layers(l2_name_list=l2_list_ice, obs_name='CryoSat2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Or for the **independent validation period**, by defining a `baseline_date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = validator_ice.get_validation_plot_for_layers(l2_name_list=l2_list_ice, obs_name='CryoSat2',\n",
    "                                                   baseline_date='2020-01-01')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Another available data source for our test glacier is **in-situ mass balance observations** from **[WGMS](https://wgms.ch/)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_ice['WGMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_args_ice['WGMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "For this dataset as well, the **CryoSat-2–calibrated data cube** outperforms the **Hugonnet-calibrated data cube** for most metrics. This highlights the **added value of Earth observation data**, confirmed through validation against **independent in-situ measurements**.\n",
    "\n",
    "Visualisations are also available for the **in-situ data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_ice.get_validation_plot_for_layers(l2_name_list=l2_list_ice, obs_name='WGMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Austria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "In Austria, we have **EO data** from **[ENVEO](https://www.enveo.at/)** (Sentinel-2), as well as **in-situ observations** from **WGMS** for some glaciers. See [this notebook](01_L1_datacubes.ipynb) for further explanations of the available data.\n",
    "\n",
    "Let’s see which **L2 data cubes** are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_tree_aut.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "In this case, we compare the impact of **two different mass balance models** that both use the same calibration data from **[Hugonnet et al. (2021)](https://doi.org/10.1038/s41586-021-03436-z)** over the period **2010–2020**.\n",
    "\n",
    "The first model is a **daily temperature-index model**, which is equivalent to the **OGGM v1.6.2 default approach**, but implemented at **daily resolution**. The second model is a **temperature-index model enhanced with a bucket-based snow-tracking scheme**. This model follows the approach described in **[Schuster et al. (2023)](https://doi.org/10.1017/aog.2023.57)** and in the **[OGGM mass-balance sandbox](https://github.com/OGGM/massbalance-sandbox)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_list_aut = ['L2_Daily_Hugonnet_2000_2020', 'L2_SfcDaily_Hugonnet_2000_2020']\n",
    "\n",
    "validation_data_aut, bootstrap_args_aut = validator_aut.get_validation_for_layers(\n",
    "    l2_name_list=l2_list_aut, return_bootstrap_args=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "You may see a warning message indicating that some data cubes are missing data for the validation. This happens because validation with **Sentinel-2 data** requires a **modelled snowline**, which is only available when using the newly implemented **snow-tracking bucket system**.\n",
    "\n",
    "We will return to this point later. For now, we first look at the **WGMS-based validation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_aut['WGMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_args_aut['WGMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "The comparison of the two options shows **slightly better performance** for the **daily model without snow tracking**.\n",
    "\n",
    "Let’s visualise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_aut.get_validation_plot_for_layers(l2_name_list=l2_list_aut, obs_name='WGMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "For the **surface-tracking model**, we see that the **extreme year 2022** is captured much better. This improvement is likely related to the **bucket-based snow-tracking system**, which implicitly includes **albedo feedbacks**. In 2022, the glacier surface became snow-free very early, leading to a **darker surface** and therefore **enhanced ablation**.\n",
    "\n",
    "However, the newly developed **bucket system** still requires further research and development before it can be considered operational.\n",
    "\n",
    "A promising future direction is the **assimilation of snowline observations**. By including surface tracking, we are able to make use of this new type of **EO data**, in particular **snowline altitudes derived from Sentinel-2**. In the current implementation, these data are used **only for validation**, but future developments should make it possible to also include them directly in the **assimilation pipeline**.\n",
    "\n",
    "The validation metrics of this first implementation are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_aut['Sentinel2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "The modelled snowline evolution can also be **visualised** together with the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_aut.get_validation_plot_for_layers(l2_name_list=l2_list_aut, obs_name='Sentinel2',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "The plot is quite dense when shown over the full period. Therefore, you can use `x_lim` to zoom in on a specific period of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_aut.get_validation_plot_for_layers(l2_name_list=l2_list_aut, obs_name='Sentinel2',\n",
    "                                             x_lim=[2020, 2022])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
