{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://notebooks.dtcglaciers.org/_images/ESA_logo.svg\" width=\"160\" align='right'/>\n",
    "</div>\n",
    "\n",
    "# Creating DTC-Glaciers EO-Native data cubes (L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "If required, install the DTCG API using the following command:\n",
    "\n",
    "```\n",
    "!pip install 'dtcg[jupyter] @ git+https://github.com/DTC-Glaciers/dtcg'\n",
    "```\n",
    "\n",
    "Run this command in a notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import dtcg.integration.oggm_bindings as oggm_bindings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In this notebook we focuse on the creation of EO-Native Data cubes, in the following called **L1** data cubes. Those **L1** data cubes consist only of Earth Observation (EO) data and in-situ data. They are created for each glacier individually. All data within the data cube is projected on the same grid and prepared to be used within other parts of DTC-Glaciers later in the workflow.\n",
    "\n",
    "To showcase the usage of different EO data sets we focuse in this notebook on the glaciers **BrÃºarjÃ¶kull outlet glacier** in VatnajÃ¶kull Iceland and **Vernagtferner** in Ã–tztal Austria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_id_ice = \"RGI60-06.00377\"  # BrÃºarjÃ¶kull\n",
    "rgi_id_aut = \"RGI60-11.00719\"  # Vernagtferner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Extract L1 data cubes from OGGM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "DTC-Glaciers starts with glacier-domain data from the **[OGGM shop](https://docs.oggm.org/en/stable/shop.html)** (sourced from multiple providers) and packages it into a data cube. In the background this will download preprocessed **L1** data cubes from OGGM and prepares everything to run the model. Theirfore this can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcg_oggm_ice = oggm_bindings.BindingsOggmModel(rgi_id=rgi_id_ice)\n",
    "dtcg_oggm_aut = oggm_bindings.BindingsOggmModel(rgi_id=rgi_id_aut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's have a look what **OGGM** supports out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcg_oggm_aut.l1_datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The central part of each data cube is one outline for defining the domain of a glacier by adding a border around the outline. Currently we rely on the **[Randolph Glacier Inventory (RGI) v6 outlines](https://doi.org/10.7265/N5-RGI-60)** because of data availability as most of global glacier datasets available today, where processed based on those outlines. But in the future we aim to update to [RGI v7](https://www.glims.org/rgi_user_guide/welcome.html). \n",
    "\n",
    "Let's have a look at the outline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_mask_aut = dtcg_oggm_aut.l1_datacube.glacier_mask\n",
    "glacier_mask_aut.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The data cubes already contain topographic information from **[Copernicus DEM - Global and European Digital Elevation Model](https://doi.org/10.5270/ESA-c5d3d65)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcg_oggm_aut.l1_datacube.topo.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "As well as:\n",
    " - ice thickness data from **[Farinotti et al. (2019)](https://doi.org/10.1038/s41561-019-0300-3)** (consensus estimate)\n",
    " - elevation change data from **[Hugonnet et al. (2021)](https://doi.org/10.1038/s41586-021-03436-z)**\n",
    " - ice velocity data from **[ITS_LIVE](https://its-live.jpl.nasa.gov/)**\n",
    " - ice velocity and ice thickness data from **[Millan et al. (2022)](https://doi.org/10.1038/s41561-021-00885-z)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_velocity(ax, ds, prefix, subsample=5, vmax=None):\n",
    "    # subsample for vector clarity\n",
    "    ds_q = ds.isel(x=slice(None, None, subsample), y=slice(None, None, subsample))\n",
    "    \n",
    "    # background scalar field\n",
    "    ds[f\"{prefix}_v\"].plot(ax=ax, cmap=\"Blues\", vmax=vmax)\n",
    "    \n",
    "    # vector overlay\n",
    "    ax.quiver(ds_q[\"x\"], ds_q[\"y\"],\n",
    "              ds_q[f\"{prefix}_vx\"], ds_q[f\"{prefix}_vy\"],\n",
    "              color=\"black\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Farinotti et al. (2019) ice thickness (consenus estimate)\n",
    "dtcg_oggm_aut.l1_datacube.consensus_ice_thickness.plot(ax=axs[0, 0]);\n",
    "\n",
    "# Hugonnet et al. (2021) height change\n",
    "dtcg_oggm_aut.l1_datacube.hugonnet_dhdt.where(glacier_mask_aut).plot(ax=axs[0, 1]);\n",
    "\n",
    "# ITS_LIVE ice velocity\n",
    "plot_velocity(ax=axs[1, 0], ds=dtcg_oggm_aut.l1_datacube.where(glacier_mask_aut),\n",
    "              prefix='itslive')\n",
    "\n",
    "# Millan et al. (2022) ice velocity\n",
    "plot_velocity(ax=axs[1, 1], ds=dtcg_oggm_aut.l1_datacube.where(glacier_mask_aut),\n",
    "              prefix='millan', vmax=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Enhance OGGM data cubes with new observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### CryoTEMPO-EOLIS derived from CryoSat-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "As part of DTC-Glaciers we developed a method to add four **[CryoTEMPO-EOLIS](https://cryotempo-eolis.org/)** variables derived from **CryoSat-2** observations to the **L1** Data cubes.\n",
    "\n",
    "| Variable | Dims | Description |\n",
    "|---|---|---|\n",
    "| `eolis_gridded_elevation_change` | `(t,y,x)` | Time series of spatial maps of elevation change since **January 2011**. |\n",
    "| `eolis_gridded_elevation_change_sigma` | `(t,y,x)` | Uncertainty (Ïƒ) for the gridded elevation-change maps. |\n",
    "| `eolis_elevation_change_timeseries` | `(t)` | Spatially aggregated 1D elevation-change series since **January 2011**. |\n",
    "| `eolis_elevation_change_sigma_timeseries` | `(t)` | Uncertainty (Ïƒ) for the aggregated series. |\n",
    "\n",
    "For this to work on your own labtop you need to register yourself on the **[CryoTEMPO-EOLIS](https://cryotempo-eolis.org/)** website and retrive a key. You need to provide your key to DTC-Glaciers in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"SPECKLIA_API_KEY\"] = ENTER YOUR SPECKLIA API KEY HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "You can add the data using `add_data_to_l1_data cube` together with `DatacubeCryotempoEolis`. This can take some time, as up-to-date data is downloaded from the **CryoTEMPO-EOLIS** server and reprojected to the **L1** Data cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.datacube.cryotempo_eolis import DatacubeCryotempoEolis\n",
    "\n",
    "dtcg_oggm_ice.add_data_to_l1_datacube(DatacubeCryotempoEolis)\n",
    "\n",
    "dtcg_oggm_ice.l1_datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Let visualise these new datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# decode for nice plotting (we dont do this during processing as it alters the metadata)\n",
    "datacube_decoded = xr.decode_cf(dtcg_oggm_ice.l1_datacube)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(15, 5))\n",
    "datacube_decoded.eolis_gridded_elevation_change.isel(t=-1).plot(ax=axes[0], cmap='RdBu')\n",
    "datacube_decoded.eolis_gridded_elevation_change_sigma.isel(t=-1).plot(ax=axes[1])\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid('on')\n",
    "plt.suptitle(\"EOLIS Gridded Elevation Change (last time step shown) \\n Glacier: {} RGI-ID: {}\".format(dtcg_oggm_ice.gdir.name, dtcg_oggm_ice.gdir.rgi_id),\n",
    "             fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "datacube_decoded.eolis_elevation_change_timeseries.plot(ax=ax)\n",
    "ax.fill_between(\n",
    "    datacube_decoded.t,\n",
    "    datacube_decoded.eolis_elevation_change_timeseries - datacube_decoded.eolis_elevation_change_sigma_timeseries,\n",
    "    datacube_decoded.eolis_elevation_change_timeseries + datacube_decoded.eolis_elevation_change_sigma_timeseries,\n",
    "    alpha=0.5\n",
    ")\n",
    "ax.set_title(\"EOLIS Elevation Change Time Series \\n Glacier: {} RGI-ID: {}\".format(dtcg_oggm_ice.gdir.name, dtcg_oggm_ice.gdir.rgi_id),\n",
    "             fontweight='bold')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Glacier surface classification from Sentinel-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Within DTC-Glaciers [ENVEO](https://www.enveo.at/) provides a 10 m gridded product of glacier surface classification derived from **Sentinel-2** data, which can be added to the **L1** data cubes the same way as shown above.\n",
    "\n",
    "| Variable | Dims | Description |\n",
    "|---|---|---|\n",
    "| `sfc_type_data` | `(t_sfc_type,y,x)` | Glacier surface classification. |\n",
    "| `sfc_type_uncertainty` | `(t_sfc_type,y,x)` | Glacier surface classification uncertainty. |\n",
    "| `sfc_type_snowline` | `(snowcover_frac, t_sfc_type)` | Snowline altitude derived from glacier surface classification for three different snow cover area fractions (25%, 50% and 75%) per 30m elevation band. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.datacube.surface_type import DatacubeSurfaceType\n",
    "\n",
    "dtcg_oggm_aut.add_data_to_l1_datacube(DatacubeSurfaceType)\n",
    "\n",
    "dtcg_oggm_aut.l1_datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "The **snowline** was derived for model validation within DTC-Glaciers and also could be assimilated in the future. For this we aggregated the gridded glacier surface classifiaction in **30 m elevation bands** and calculated for each band the **snow cover area fraction**, excluding cloud pixels. Afterwards we looked for the lowest elevation band where one of the three tresholds 25%, 50% and 75% where exceeded first.\n",
    "\n",
    "Let's have a look at one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dtcg.datacube.surface_type import (\n",
    "    get_categories_per_elevation_band, exclude_empty_elevation_bins,\n",
    "    exclude_dates_with_to_much_cloud_cover, get_snowline)\n",
    "\n",
    "def plot_surface_classification_per_elev_band(l1_datacube, date):\n",
    "    ds_obs = get_categories_per_elevation_band(l1_datacube)\n",
    "    ds_obs = exclude_empty_elevation_bins(ds=ds_obs)\n",
    "    ds_obs = exclude_dates_with_to_much_cloud_cover(ds=ds_obs)\n",
    "\n",
    "    ds_use = ds_obs.sel(t_sfc_type=date)\n",
    "    ds_use = xr.decode_cf(ds_use)\n",
    "\n",
    "    bin_idx, bin_elev = get_snowline(ds_use)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(13, 5), gridspec_kw={'wspace':0.1})\n",
    "    \n",
    "    ax_total = axs[0]\n",
    "    ax_relative = axs[1]\n",
    "    ax_uncertainty = axs[2]\n",
    "    \n",
    "    def plot_horizontal_stacked_bar(ax, ds, categories, var, normalize=False):\n",
    "        category_dict = eval(ds[categories].attrs['code'])  # ast.literal_eval(ds[categories].attrs['code'])\n",
    "        previous_values = None\n",
    "        for category in ds_use[categories]:\n",
    "            current_values = ds.loc[{categories: category}][var].values\n",
    "            if normalize:\n",
    "                number_grid_points_elev_bin = ds.category_counts.sum(dim='category')\n",
    "                current_values = current_values.astype(float) / number_grid_points_elev_bin\n",
    "            ax.barh(ds.elevation_bin, current_values,\n",
    "                     left=previous_values,\n",
    "                     label=category_dict[int(category)])\n",
    "        \n",
    "            if previous_values is None:\n",
    "                previous_values = current_values\n",
    "            else:\n",
    "                previous_values = previous_values + current_values\n",
    "    \n",
    "        ax.invert_yaxis()\n",
    "    \n",
    "    plot_horizontal_stacked_bar(ax_total, ds_use, 'category', 'category_counts')\n",
    "    plot_horizontal_stacked_bar(ax_relative, ds_use, 'category', 'category_counts', normalize=True)\n",
    "    plot_horizontal_stacked_bar(ax_uncertainty, ds_use, 'uncertainty_flag', 'uncertainty_counts', normalize=True)\n",
    "\n",
    "    def add_snowline(ax):\n",
    "        if np.isneginf(bin_elev[1]):\n",
    "            extra_label = 'fully snow covered'\n",
    "        elif np.isposinf(bin_elev[1]):\n",
    "            extra_label = 'fully snow free'\n",
    "        else:\n",
    "            extra_label = f'{bin_elev[1]:.0f} m'\n",
    "        ax.axhline(bin_idx[0], color='k', linestyle='--')\n",
    "        ax.axhline(bin_idx[1], color='k', linestyle='-', label=f'snowline ({extra_label})')\n",
    "        ax.axhline(bin_idx[2], color='k', linestyle='--', label='snowline uncertainty')\n",
    "\n",
    "    def set_legend(ax):\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05))\n",
    "    \n",
    "    ax_total.set_yticks(ds_use.elevation_bin, [int(elev) for elev in ds_use.lower_elevation.values])\n",
    "    ax_total.set_ylabel('Altitude [m]')\n",
    "    ax_total.set_title('category count')\n",
    "    add_snowline(ax_total)\n",
    "    set_legend(ax_total)\n",
    "    \n",
    "    ax_relative.set_title('category count relative')\n",
    "    ax_relative.set_yticklabels([])\n",
    "    add_snowline(ax_relative)\n",
    "    set_legend(ax_relative)\n",
    "    \n",
    "    ax_uncertainty.set_title('uncertainty count relative')\n",
    "    ax_uncertainty.set_yticklabels([])\n",
    "    add_snowline(ax_uncertainty)\n",
    "    set_legend(ax_uncertainty)\n",
    "\n",
    "    fig.suptitle(f\"{l1_datacube.attrs['RGI-ID']}, {np.datetime_as_string(ds_use.t_sfc_type.values, unit='D')}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surface_classification_per_elev_band(\n",
    "    l1_datacube=dtcg_oggm_aut.l1_datacube,\n",
    "    date=dtcg_oggm_aut.l1_datacube.t_sfc_type[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Let's visualize the derived snowline on top of the original gridded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "def build_categorical_colormap(class_labels, palette_name=\"colorblind\"):\n",
    "\n",
    "    # Extract integer classes and sort them\n",
    "    classes = sorted([k for k in class_labels.keys() if isinstance(k, (int, np.integer))])\n",
    "    n = len(classes)\n",
    "\n",
    "    # Pick n colors from seaborn palette\n",
    "    colors = sns.color_palette(palette_name, n)\n",
    "\n",
    "    # Create colormap\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    \n",
    "    # Set NaN color (\"bad\" values)\n",
    "    #cmap.set_bad(\"lightgray\")\n",
    "\n",
    "    # Boundaries between classes â€” last boundary is +1\n",
    "    bounds = [c - 0.5 for c in classes] + [classes[-1] + 0.5]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    return norm, cmap, classes\n",
    "\n",
    "\n",
    "def plot_gridded_surface_classification(l1_datacube, date, x_zoom=70, y_zoom=50, snowline=None):\n",
    "    \n",
    "    ds_plot = l1_datacube.isel(x=slice(x_zoom, len(l1_datacube.x) - x_zoom),\n",
    "                               y=slice(y_zoom, len(l1_datacube.y) - y_zoom))\n",
    "\n",
    "    ds_plot = ds_plot.sel(t_sfc_type=date)\n",
    "    ds_plot = xr.decode_cf(ds_plot)\n",
    "    \n",
    "    # Integer classes in your dataset\n",
    "    dict_labels_1 = {0: 'unclassified',\n",
    "     1: 'snow',\n",
    "     2: 'firn \\n old snow \\n bright ice',\n",
    "     3: 'clean ice',\n",
    "     4: 'debris',\n",
    "     5: 'cloud',\n",
    "     'nan': 'no data'}#ast.literal_eval(ds_plot.sfc_type_data.code)\n",
    "    \n",
    "    dict_labels_2 = {1: 'low uncertainty \\n illuminated pixel',\n",
    "     2: 'medium uncertainty \\n illuminated pixel',\n",
    "     3: 'high uncertainty \\n illuminated pixel',\n",
    "     5: 'cloud',\n",
    "     11: 'low uncertainty \\n shaded pixel',\n",
    "     12: 'medium uncertainty \\n shaded pixel',\n",
    "     13: 'high uncertainty \\n shaded pixel',\n",
    "     'nan': 'no data'}#ast.literal_eval(ds_plot.sfc_type_uncertainty.code)\n",
    "    \n",
    "    norm_1, cmap_1, classes_1 = build_categorical_colormap(dict_labels_1)\n",
    "    norm_2, cmap_2, classes_2 = build_categorical_colormap(dict_labels_2)\n",
    "    \n",
    "    # Your data array\n",
    "    da_1 = ds_plot.where(ds_plot.glacier_mask).sfc_type_data\n",
    "    da_2 = ds_plot.where(ds_plot.glacier_mask).sfc_type_uncertainty\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    ax_1 = axs[0]\n",
    "    ax_2 = axs[1]\n",
    "    \n",
    "    mappable_1 = da_1.plot(ax=ax_1, cmap=cmap_1, norm=norm_1, add_colorbar=False)\n",
    "    mappable_2 = da_2.plot(ax=ax_2, cmap=cmap_2, norm=norm_2, add_colorbar=False)\n",
    "    \n",
    "    # add derived snowline\n",
    "    \n",
    "    cs = ds_plot.where(ds_plot.glacier_mask).topo_smoothed.plot.contour(\n",
    "        ax=ax_1, levels=[snowline], colors='k', linewidths=0.5)\n",
    "    proxy = mlines.Line2D([], [], color=\"k\", linewidth=0.5, label=f'derived snowline at {snowline} m')\n",
    "    ax_1.legend(handles=[proxy])\n",
    "\n",
    "    cs = ds_plot.where(ds_plot.glacier_mask).topo_smoothed.plot.contour(\n",
    "        ax=ax_2, levels=[snowline], colors='k', linewidths=0.5)\n",
    "    proxy_2 = mlines.Line2D([], [], color=\"k\", linewidth=0.5, label=f'derived snowline at {snowline} m')\n",
    "    ax_2.legend(handles=[proxy_2])\n",
    "    \n",
    "    # Add labeled colorbar\n",
    "    cbar_1 = plt.colorbar(mappable_1, ax=ax_1, orientation='horizontal', ticks=classes_1)\n",
    "    cbar_1.ax.set_xticklabels([f\"{dict_labels_1[c]}\" for c in classes_1], rotation=90)\n",
    "    cbar_1.set_label(ds_plot.sfc_type_data.long_name)\n",
    "    \n",
    "    cbar_2 = plt.colorbar(mappable_2, ax=ax_2, ticks=[1, 2, 3.5, 7.5, 11, 12, 13], orientation='horizontal')#classes_2)\n",
    "    cbar_2.ax.set_xticklabels([f\"{dict_labels_2[c]}\" for c in classes_2], rotation=90)\n",
    "    cbar_2.set_label(ds_plot.sfc_type_uncertainty.long_name)\n",
    "    \n",
    "    ax_1.axis('equal')\n",
    "    ax_2.axis('equal')\n",
    "    \n",
    "    ax_1.set_title(f\"{l1_datacube.attrs['RGI-ID']}, {np.datetime_as_string(da_1.t_sfc_type.values, unit='D')}\")\n",
    "    ax_2.set_title(f\"{l1_datacube.attrs['RGI-ID']}, {np.datetime_as_string(da_2.t_sfc_type.values, unit='D')}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridded_surface_classification(\n",
    "    l1_datacube=dtcg_oggm_aut.l1_datacube,\n",
    "    date=dtcg_oggm_aut.l1_datacube.t_sfc_type[1],\n",
    "    snowline=3120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### In-situ mass balance observations from WGMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "For validation, DTC-Glaciers can add in-situ mass balance observations from **[WGMS](https://wgms.ch/)** to the **L1** data cubes for glaciers where those observations are available, in the same manner as seen above.\n",
    "\n",
    "| Variable | Dims | Description |\n",
    "|---|---|---|\n",
    "| `wgms_mb` | `(t_wgms)` | Specific mass balance observation as reported tothe World Glacier Monitoring Service. |\n",
    "| `wgms_mb_unc` | `(t_wgms)` | Specific mass balance observation uncertainty as reported to the World Glacier Monitoring Service. If no value was reported it is set to 200 mm w.e.. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.datacube.wgms import DatacubeWGMS\n",
    "\n",
    "dtcg_oggm_ice.add_data_to_l1_datacube(DatacubeWGMS)\n",
    "\n",
    "dtcg_oggm_ice.l1_datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x=dtcg_oggm_ice.l1_datacube.t_wgms,\n",
    "             y=dtcg_oggm_ice.l1_datacube.wgms_mb,\n",
    "             yerr=dtcg_oggm_ice.l1_datacube.wgms_mb_unc,\n",
    "             fmt=\".--\", capsize=2)\n",
    "plt.grid(\"on\")\n",
    "plt.ylabel(\"Specific MB (mm w.e. yr-1)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(dtcg_oggm_ice.l1_datacube.attrs[\"RGI-ID\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Apply CF Convention and Export as GeoZarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "After the creation of the enhanced **L1** Datacube we can update the metadata for all variables following the **[CF Convention](https://cfconventions.org/Data/cf-conventions/cf-conventions-1.11/cf-conventions.pdf)** by using the DTC-Glaciers `GeoZarrHandler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtcg.datacube.geozarr import GeoZarrHandler\n",
    "\n",
    "datacube_handler_aut = GeoZarrHandler(dtcg_oggm_aut.l1_datacube)\n",
    "\n",
    "datacube_handler_aut.data_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "[![Zarr logo](https://avatars.githubusercontent.com/u/35050297?s=96&v=4)](https://github.com/zarr-developers/geozarr-spec) The resulting **L1** data cube can be exported as a GeoZarr with the data cube's export function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory(suffix=\".zarr\") as tmpdir:\n",
    "    output_path = Path(tmpdir)\n",
    "    datacube_handler_aut.export(output_path)\n",
    "    print(f\"âœ… GeoZarr exported to: {output_path}\")\n",
    "    items = sorted(p.name for p in output_path.iterdir())\n",
    "    print(\"ðŸ“‚ Top-level contents:\", \", \".join(items) or \"(empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Preprocessed data cubes for case study regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Preprocessed **L1** data cubes include all currently supported observations, for the case study regions in Iceland and Austria are available at https://cluster.klima.uni-bremen.de/~dtcg/data cubes_case_study_regions/L1/ and are available at and can be streamed via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "datacube_url = \"https://cluster.klima.uni-bremen.de/~dtcg/datacubes_case_study_regions/L1/\"\n",
    "def get_data_tree(rgi_id):\n",
    "    return xr.open_datatree(\n",
    "            f\"{datacube_url}{rgi_id}.zarr\",\n",
    "            chunks={},\n",
    "            engine=\"zarr\",\n",
    "            consolidated=True,\n",
    "            decode_cf=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "These, together with the **L2** data cubes explained in [this notebook](02_L2_datacubes.ipynb) are available for all RGI6 glaciers of VatnajÃ¶kull ([view in OpenStreetMap](https://www.openstreetmap.org/#map=8/64.438/-17.312)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from oggm import utils\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "dtcf_url = 'https://cluster.klima.uni-bremen.de/~dtcg/test_files/case_study_regions/iceland/'\n",
    "with open(utils.file_downloader(dtcf_url + 'vatnajokull_rgi_ids.yml'), 'r') as yaml_file:\n",
    "    rgi_ids = yaml.safe_load(yaml_file)['rgi_ids']\n",
    "\n",
    "# Select the outlines from RGI6 file and convert to UTM\n",
    "rgi_file = gpd.read_file(utils.get_rgi_region_file('06'))\n",
    "rgi_file = rgi_file.loc[rgi_file.RGIId.isin(rgi_ids)].set_index('RGIId')\n",
    "rgi_file = rgi_file.to_crs('EPSG:32628')\n",
    "\n",
    "rgi_file.plot(ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Another example is the Ã–tztal region in the Austrian Alps ([view in OpenStreetMap](https://www.openstreetmap.org/#map=10/46.9864/10.9101)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dtcf_url = 'https://cluster.klima.uni-bremen.de/~dtcg/test_files/case_study_regions/austria/'\n",
    "with open(utils.file_downloader(dtcf_url + 'oeztal_rgi_ids.json'), 'r') as json_file:\n",
    "    rgi_ids = json.load(json_file)\n",
    "\n",
    "# Select the outlines from RGI6 file and convert to UTM\n",
    "rgi_file = gpd.read_file(utils.get_rgi_region_file('11'))\n",
    "rgi_file = rgi_file.loc[rgi_file.RGIId.isin(rgi_ids)].set_index('RGIId')\n",
    "rgi_file = rgi_file.to_crs('EPSG:32628')\n",
    "\n",
    "rgi_file.plot(ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "To get the RGI6-ID of the glacier you are interested in you can use the [GlimsViewer](https://www.glims.org/maps/glims). You need to enable the RGIv6-IDs in the menu in the top right corner, zoom to the glacier outline of interest and click on it to display its metadata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
